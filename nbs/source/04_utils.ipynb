{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Definition of utility functions that deal with simple but recurrent transformations.\n",
    "output-file: utils.html\n",
    "title: Utils\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import io\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from fastcore.all import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_trainings(training_results, eval_optims=True, expl_optims=False, figsize=(10, 5),\n",
    "                   fontsize=18, ticksize=14):\n",
    "    \"Plots the training results.\"\n",
    "    use_legend = eval_optims or expl_optims\n",
    "    mean_rewards = np.mean(training_results['rewards'], axis=0)\n",
    "    std_rewards = np.std(training_results['rewards'], axis=0)\n",
    "    mean_costs = np.mean(training_results['costs'], axis=0)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    color1 = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"Training episodes\", fontsize=fontsize)\n",
    "    ax1.set_ylabel(\"Reward\", color=color1, fontsize=fontsize)\n",
    "    ax1.plot(mean_rewards, alpha=0.8, label=\"Rewards\")\n",
    "    ax1.set_ylim([-0.05, 1.05]); ax1.set_yticks(np.arange(11, step=2)/10)\n",
    "    if eval_optims: \n",
    "        ax1.plot(np.mean(training_results['eval_optims'], axis=0), alpha=0.8, color='C3',\n",
    "                 label=\"Optims eval\")\n",
    "    if expl_optims: \n",
    "        ax1.plot(np.mean(training_results['expl_optims'], axis=0), alpha=0.8, color='C4',\n",
    "                 label=\"Optims expl\")\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.tick_params(labelsize=ticksize)\n",
    "    ax1.grid()\n",
    "    if use_legend: plt.legend(loc='best', fontsize=ticksize)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = \"tab:orange\"\n",
    "    ax2.set_ylabel(\"Cost\",color=color2,fontsize=fontsize)\n",
    "    ax2.plot(mean_costs,color=color2,alpha=0.5,label=\"Cost\")\n",
    "    ax2.tick_params(axis='y', labelcolor=color2, labelsize=ticksize)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def arrange_shape(obj, mode='expand'):\n",
    "    \"Makes all lists within a list have the same length. Can be mode 'cut' or 'expand'\"\n",
    "    rows = len(obj)\n",
    "    if mode == 'expand':\n",
    "        cols = max([len(obj[k]) for k in range(rows)])\n",
    "        M = np.zeros((rows, cols))\n",
    "        for r in range(rows):\n",
    "            list_length = len(obj[r])\n",
    "            M[r, :] = obj[r] + [obj[r][-1]]*(cols-list_length)\n",
    "    elif mode == 'cut':\n",
    "        cols = min([len(obj[k]) for k in range(rows)])\n",
    "        M = np.zeros((rows, cols))\n",
    "        for r in range(rows):\n",
    "            M[r, :] = obj[r][:cols]\n",
    "        \n",
    "    return M\n",
    "\n",
    "def best_so_far(m):\n",
    "    \"Returns best value up to each point along the second axis of a matrix for each row.\"\n",
    "    m = np.array(m)\n",
    "    M = np.zeros_like(m)\n",
    "    for k in range(M.shape[-1]):\n",
    "        M[:, k] = np.max(m[:, :k+1], axis=1)\n",
    "    return M\n",
    "\n",
    "def plot_exploration(exploration_results, expl_optims=True, highlight_max=False, figsize=(10, 5),\n",
    "                     fontsize=18, ticksize=14):\n",
    "    \"\"\"Plots exploration results. It shows the best bound obtained for every new visited state.\n",
    "    If `expl_optims=True`, it also shows the proximity to the optimal relaxation.\"\"\"\n",
    "    bounds = arrange_shape(exploration_results['bounds'])\n",
    "    best_bounds = best_so_far(bounds).T\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    color = \"tab:blue\"\n",
    "    ax.plot(best_bounds, color=color, alpha=0.3)\n",
    "    ax.plot(np.mean(best_bounds, axis=-1), linewidth=4, color=color)\n",
    "    if highlight_max: ax.plot(np.max(best_bounds, axis=-1), color='C3')\n",
    "    ax.tick_params(labelsize=ticksize)\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(\"Best obtained bound\", fontsize=fontsize)\n",
    "    ax.set_xlabel(\"New visited state\", fontsize=fontsize)\n",
    "    \n",
    "    if expl_optims:\n",
    "        ax.set_ylabel(\"Best obtained bound\", color=color, fontsize=fontsize)\n",
    "        ax.tick_params(axis='y', labelcolor=color)\n",
    "        opt = arrange_shape(exploration_results['oracle_rewards'])\n",
    "        best_opt = best_so_far(opt).T\n",
    "        ax2 = ax.twinx()\n",
    "        color2 = \"tab:orange\"\n",
    "        ax2.plot(np.mean(best_opt, axis=-1), color=color2, linewidth=2)\n",
    "        ax2.set_ylabel(\"Optimality\",color=color2,fontsize=fontsize)\n",
    "        ax2.tick_params(axis='y', labelcolor=color2, labelsize=ticksize)  \n",
    "        ax2.set_ylim([-0.05, 1.05])\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convergence_time(results, tol=5e-4, T=50, t_avg=20, return_diffs=False):\n",
    "    \"Returns the convergence with criterion of not changing result by `tol` for `T` epochs.\"\n",
    "    if 'training' in results.keys(): results = results['training']\n",
    "    rewards = arrange_shape(results['rewards'])\n",
    "    mean_rewards = np.mean(rewards, axis=0)\n",
    "    epochs = len(mean_rewards)\n",
    "    moving_avg = np.convolve(np.array([1/t_avg]*t_avg), mean_rewards, mode='valid')\n",
    "    diffs = np.abs(moving_avg[1:] - moving_avg[:-1])\n",
    "    diff_variation = np.convolve(np.array([1/T]*T), diffs, mode='valid')\n",
    "    try:    t = np.where(diff_variation <= tol)[0][0]\n",
    "    except: t = len(mean_rewards)\n",
    "    if return_diffs: return t + 2*T, moving_avg, diff_variation \n",
    "    return t + T\n",
    "\n",
    "@delegates(convergence_time)\n",
    "def indiv_convergence_time(results, max_epochs=800, **kwargs):\n",
    "    \"Similar to `convergence_time` but with each agent.\"\n",
    "    results = results['rewards']\n",
    "    times = [convergence_time({'rewards': [res[:max_epochs]]}, **kwargs) for res in results]\n",
    "    return np.array(times)\n",
    "\n",
    "def get_indiv_times(tl_eval, convergence_crit=None):\n",
    "    \"Provides convergence times from individual ratios.\"\n",
    "    default_crit = {'T': 50, 't_avg': 100, 'tol': 2e-4}\n",
    "    convergence_crit = {**default_crit, **convergence_crit} if convergence_crit is not None else default_crit\n",
    "    Bs = list(TL_evaluation.keys()); Bs.sort()\n",
    "    time_ratios, time_err = [], []\n",
    "    for b in Bs:\n",
    "        ts_tl = indiv_convergence_time(tl_eval[b]['tl'], **convergence_crit)\n",
    "        ts_0 = indiv_convergence_time(tl_eval[b]['vanilla'], **convergence_crit)\n",
    "        t0, ttl = ts_0.mean(), ts_tl.mean()\n",
    "        ratio = ttl/t0\n",
    "        ratio_std = np.sqrt((1/t0)**2*ts_tl.var() + (ttl/t0**2)**2*ts_0.var())\n",
    "        time_ratios.append(ratio)\n",
    "        time_err.append(ratio_std/np.sqrt(len(ts_0)))\n",
    "    return Bs, np.array(time_ratios), np.array(time_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    \"Unpickles from GPU to CPU\"\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "bench_dir  = Path(\"../benchmarks/\")\n",
    "ckp_dir    = Path(\"../trained_models/checkpoints/\")\n",
    "agents_dir = Path(\"../trained_models/\")\n",
    "\n",
    "def get_problem_file_name(problem):\n",
    "    \"Returns a consistent file naming from a problem instance.\"\n",
    "#     supports = '_'.join([state2str(i[0]) for i in problem.to_sdp()])\n",
    "    graph = problem.graph.__class__.__name__\n",
    "    terms = terms = '_'.join([f'{problem._get_weight(i[1]):.2f}' for i in problem.to_sdp()])\n",
    "    return f\"{problem.name}_N{problem.graph.n_nodes}_{graph}_terms_{terms}\"\n",
    "\n",
    "def get_agent_file_name(problem, budget, ID):\n",
    "    \"Returns a consistent file naming for agents.\"\n",
    "    return f\"agent_{ID}_budget_{budget}_{get_problem_file_name(problem)}\"\n",
    "\n",
    "def get_memory_file_name(problem, solver):\n",
    "    \"Returns a consistent file naming for memories.\"\n",
    "    solver_name = re.findall('SdP(.*?)Solver', solver.__class__.__name__)[0]\n",
    "    return f\"memory_{solver_name}_{get_problem_file_name(problem)}\"\n",
    "\n",
    "def get_benchmark_file_name(problem, budget, method):\n",
    "    \"Returns a consistent file naming for benchmarks.\"\n",
    "    return f\"bench_{method}_budget_{budget}_{get_problem_file_name(problem)}\"\n",
    "\n",
    "def get_checkpoint_file_name(problem, budget, ID, episode):\n",
    "    \"Returns a consistent file naming for checkpoints.\"\n",
    "    return f\"ckp_{ID}_e_{episode}_budget_{budget}_{get_problem_file_name(problem)}\"\n",
    "\n",
    "def save_model(agent, problem, budget, ID):\n",
    "    \"Saves agent model and parameters.\"\n",
    "    agent_name = f\"{get_agent_file_name(problem, budget, ID)}.pt\" \n",
    "    torch.save({'model': agent.model, 'state_dict': agent.model.state_dict}, agents_dir/agent_name)\n",
    "\n",
    "def load_model(problem, budget, ID):\n",
    "    \"Loads agent model and parameters.\"\n",
    "    agent_name = f\"{get_agent_file_name(problem, budget, ID)}.pt\"        \n",
    "    return torch.load(agents_dir/agent_name)\n",
    "\n",
    "def save_benchmark(benchmark, problem, budget, method, suffix=None):\n",
    "    \"Saves benchmark data.\"\n",
    "    bench_dir.mkdir(exist_ok=True)\n",
    "    file_name = get_benchmark_file_name(problem, budget, method)\n",
    "    if suffix is not None: file_name += f\"_{suffix}\"\n",
    "    save_path = (bench_dir/file_name).with_suffix(\".pkl\")\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(benchmark, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_benchmark(problem, budget, method, suffix=None):\n",
    "    \"Loads benchmark data.\"\n",
    "    file_name = get_benchmark_file_name(problem, budget, method)\n",
    "    if suffix is not None: file_name += f\"_{suffix}\"\n",
    "    load_path = (bench_dir/file_name).with_suffix(\".pkl\")\n",
    "    with open(load_path, \"rb\") as f:\n",
    "        benchmark = pickle.load(f)\n",
    "    return benchmark\n",
    "\n",
    "def load_checkpoint(problem, budget, ID, episode):\n",
    "    ckp_name = f\"{get_checkpoint_file_name(problem, budget, ID, episode)}.pt\"\n",
    "    return torch.load(ckp_dir/ckp_name)\n",
    "\n",
    "def checkpoint2results(N, model, budget=None, IDs=None, episode=None):\n",
    "    \"Loads checkpoints from IDs and converts them to result format.\"\n",
    "    models, envs = [], []\n",
    "    final_rewards, final_costs, final_bounds, final_optims, expl_optims = [], [], [], [], []\n",
    "    visited_states, visited_bounds, visited_costs = [], [], []\n",
    "    oracle_rewards, visited_rewards = [], []\n",
    "    if IDs is None:\n",
    "        ckp_paths = [c for c in ckp_dir.ls() if f\"N{N}\" in str(c) and f\"{model}\" in str(c)]\n",
    "        if budget is not None:  ckp_paths = [c for c in ckp_paths if f\"budget_{budget}_\" in str(c)]\n",
    "        if episode is not None: ckp_paths = [c for c in ckp_paths if f\"e_{episode}\" in str(c)]\n",
    "        checkpoints = [torch.load(c) for c in ckp_paths]\n",
    "    else:\n",
    "        # Weird function behaviour, I know. For now, I just need to get through this.\n",
    "        checkpoints = []\n",
    "        for ID in IDs:\n",
    "            try:    checkpoints.append(load_checkpoint(N, model, budget, ID, episode))\n",
    "            except: print(f\"Failed to load ID{ID}\")\n",
    "    for ckp in checkpoints:\n",
    "        models.append(ckp['model']); envs.append(ckp['env']); final_rewards.append(ckp['final_reward'])\n",
    "        final_costs.append(ckp['final_costs']); final_bounds.append(ckp['final_bounds'])\n",
    "        final_optims.append(ckp['eval_optims']); expl_optims.append(ckp['expl_optims'])\n",
    "        visited_states.append(ckp['visited_states']); visited_bounds.append(ckp['visited_bounds'])\n",
    "        visited_costs.append(ckp['visited_costs']); oracle_rewards.append(ckp['oracle_rewards'])\n",
    "        visited_rewards.append(ckp['visited_rewards'])\n",
    "            \n",
    "    training_results = {'models': models, 'envs': envs, 'rewards': final_rewards,\n",
    "                        'costs': final_costs, 'bounds': final_bounds, 'eval_optims': final_optims, \n",
    "                        'expl_optims': expl_optims}\n",
    "    exploration_results = {'agents': models, 'envs': envs, 'visited_states': visited_states,\n",
    "                           'bounds': visited_bounds, 'costs': visited_costs,\n",
    "                           'oracle_rewards': oracle_rewards, 'visited_rewards': visited_rewards}\n",
    "    return {'training': training_results, 'exploration': exploration_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def simplify_layout(L):\n",
    "    \"Simplifies the given layout of the form `[np.array([0, 1]), np.array([0, 1, 2])]`.\"\n",
    "    to_simplify = []\n",
    "    for k1, sites1 in enumerate(L[:-1]):\n",
    "        if k1 not in to_simplify:\n",
    "            for k2, sites2 in enumerate(L[k1+1:]):\n",
    "                overlap = len(np.intersect1d(sites1, sites2))\n",
    "                if   overlap == len(sites1): to_simplify.append(k1); break\n",
    "                elif overlap == len(sites2): to_simplify.append(k1+1+k2)\n",
    "    return [sites for k, sites in enumerate(L) if k not in to_simplify]\n",
    "\n",
    "def fill_layout(L, N):\n",
    "    \"Fills layout with single-body terms that are missing.\"\n",
    "    for n in range(N):\n",
    "        included = any([(sites == n).any() for sites in L])\n",
    "        if not included: L.append(np.array([n]))\n",
    "    return L\n",
    "    \n",
    "def state2int(state):\n",
    "    \"Takes state vector as binary encoding of an integer.\"\n",
    "    return int(state2str(state[::-1]), 2)\n",
    "\n",
    "def state2str(state):\n",
    "    \"Takes state vector and outputs a (spaceless) string.\"\n",
    "    return ''.join(str(int(i)) if isinstance(i, (int, np.int64)) or i.is_integer() else str(i) for i in state)\n",
    "    \n",
    "def T(state):\n",
    "    \"Takes state and converts it to `torch.FloatTensor`\"\n",
    "    return torch.FloatTensor(state)\n",
    "    \n",
    "def flip(state, i):\n",
    "    \"Flips constraint `i` from state.\"\n",
    "    flip_state = deepcopy(state)\n",
    "    flip_state[i] = -flip_state[i] + 1\n",
    "    return flip_state\n",
    "\n",
    "def add_subgraph_size(subgraphs):\n",
    "    \"\"\"Takes a list of subgraphs up to any given size and adds a sublist with all the possible\n",
    "    subgraphs of a larger size. It assumes the graph edges as minimal graph size.\"\"\"\n",
    "    new_subgraphs = []\n",
    "    for edge in subgraphs[0]:\n",
    "        for subgraph in subgraphs[-1]:\n",
    "            if len(np.intersect1d(edge, subgraph)) == 1:\n",
    "                new_subgraph = np.unique(np.concatenate((edge, subgraph)))\n",
    "                if not array_in_list(new_subgraph, new_subgraphs):\n",
    "                    new_subgraphs.append(new_subgraph)\n",
    "    if len(new_subgraphs) == 0: return subgraphs\n",
    "    return [*subgraphs, new_subgraphs]\n",
    "\n",
    "def contained_constraints(state, basis):\n",
    "    \"\"\"Returns a mask indicating which constraints in the `state` are contained by larger elements\n",
    "    of the basis in the same state, excluding themselves. Better to use the\n",
    "    `SdPEnvironment.contained_constraints` method when possible (it's faster).\"\"\"\n",
    "    contained = np.zeros_like(state, dtype=bool)\n",
    "    active = basis[state.astype(bool)]\n",
    "    for i, supp in enumerate(basis):\n",
    "        for supp_active in active:\n",
    "            common = np.intersect1d(supp, supp_active) \n",
    "            if (len(common) == len(supp)) and (len(common) < len(supp_active)):\n",
    "                contained[i] = True\n",
    "                break\n",
    "    return contained\n",
    "    \n",
    "def action_mask(state, basis):\n",
    "    \"\"\"Mask of the actions that can be performed. Better to use `SdPEnvironment.action_mask` if\n",
    "    possible, it's much faster.\"\"\"\n",
    "    return np.concatenate(~contained_constraints(state, basis), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def array_in_list(array, array_list):\n",
    "    \"Checks whether an array is in a list of arrays.\"\n",
    "    return any((array == x).all() for x in array_list)\n",
    "\n",
    "def arrayfy(inp, size):\n",
    "    \"Transforms input into an array of the desired size.\"\n",
    "    if isinstance(inp, Iterable): inp = list(inp)\n",
    "    else:                         inp = [inp]\n",
    "    return np.array(np.ceil(size/len(inp)).astype(int)*inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export     \n",
    "def dist_exp(xmin, x):\n",
    "    \"\"\"Computes an eponential distance given a minimum value (in terms of absolute value).\"\"\"\n",
    "    return np.exp(1-x/xmin)\n",
    "\n",
    "def dist_poly(x, xmin, xmax, d):\n",
    "    \"\"\"Computes a linear decay bound from 1 to 0 given a minimum and maximum value (in terms of \n",
    "    absolute value). Exponentiate the line to get better shapes\"\"\"\n",
    "    if np.allclose(xmin, xmax): x[:] = 1.; return x \n",
    "    else:                       return ((x-xmax)/(xmin-xmax))**d \n",
    "    \n",
    "def binomial(n, k):\n",
    "    return np.math.factorial(n)/(np.math.factorial(k)*np.math.factorial(n-k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_environment.ipynb.\n",
      "Converted 01_agents.ipynb.\n",
      "Converted 02_budget_profiles.ipynb.\n",
      "Converted 03_hamiltonian.ipynb.\n",
      "Converted 04_training.ipynb.\n",
      "Converted 05_utils.ipynb.\n",
      "Converted 06_sdp.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
