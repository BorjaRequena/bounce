{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import io\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from fastcore.all import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from nbdev.export import notebook2script\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Utils\n",
    "\n",
    "> Definition of utility functions that deal with simple but recurrent transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_trainings(training_results, eval_optims=True, expl_optims=False):\n",
    "    \"Plots the training results.\"\n",
    "    use_legend = eval_optims or expl_optims\n",
    "    mean_rewards = np.mean(training_results['rewards'], axis=0)\n",
    "    std_rewards = np.std(training_results['rewards'], axis=0)\n",
    "    mean_params = np.mean(training_results['params'], axis=0)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    color1 = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"episodes\", fontsize=18)\n",
    "    ax1.set_ylabel(\"Reward\", color=color1, fontsize=18)\n",
    "    ax1.plot(mean_rewards, alpha=0.8, label=\"Rewards\")\n",
    "    ax1.set_ylim([-0.05, 1.05]); ax1.set_yticks(np.arange(11, step=2)/10)\n",
    "    if eval_optims: ax1.plot(np.mean(training_results['eval_optims'], axis=0), alpha=0.8, color='C3', label=\"Optims eval\")\n",
    "    if expl_optims: ax1.plot(np.mean(training_results['expl_optims'], axis=0), alpha=0.8, color='C4', label=\"Optims expl\")\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.grid()\n",
    "    if use_legend: plt.legend(loc='best')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = \"tab:orange\"\n",
    "    ax2.set_ylabel(\"Parameters\",color=color2,fontsize=18)\n",
    "    ax2.plot(mean_params,color=color2,alpha=0.5,label=\"Params\")\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def arrange_shape(obj, mode='expand'):\n",
    "    \"Makes all lists within a list to have the same length. Can be mode 'cut' or 'expand'\"\n",
    "    rows = len(obj)\n",
    "    if mode == 'expand':\n",
    "        cols = max([len(obj[k]) for k in range(rows)])\n",
    "        M = np.zeros((rows, cols))\n",
    "        for r in range(rows):\n",
    "            list_length = len(obj[r])\n",
    "            M[r, :] = obj[r] + [obj[r][-1]]*(cols-list_length)\n",
    "    elif mode == 'cut':\n",
    "        cols = min([len(obj[k]) for k in range(rows)])\n",
    "        M = np.zeros((rows, cols))\n",
    "        for r in range(rows):\n",
    "            M[r, :] = obj[r][:cols]\n",
    "        \n",
    "    return M\n",
    "\n",
    "def best_so_far(m):\n",
    "    \"Returns best value up to each point along the second axis of a matrix for each row.\"\n",
    "    m = np.array(m)\n",
    "    M = np.zeros_like(m)\n",
    "    for k in range(M.shape[1]):\n",
    "        M[:, k] = np.max(m[:, :k+1], axis=1)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def convergence_time(results, tol=5e-4, T=50, t_avg=20, return_diffs=False):\n",
    "    \"Returns the convergence with criterion of not changing result by `tol` for `T` epochs.\"\n",
    "    if 'training' in results.keys(): results = results['training']\n",
    "    rewards = arrange_shape(results['rewards'])\n",
    "    mean_rewards = np.mean(rewards, axis=0)\n",
    "    epochs = len(mean_rewards)\n",
    "    moving_avg = np.convolve(np.array([1/t_avg]*t_avg), mean_rewards, mode='valid')\n",
    "    diffs = np.abs(moving_avg[1:] - moving_avg[:-1])\n",
    "    diff_variation = np.convolve(np.array([1/T]*T), diffs, mode='valid')\n",
    "    try:    t = np.where(diff_variation <= tol)[0][0]\n",
    "    except: t = len(mean_rewards)\n",
    "    if return_diffs: return t + 2*T, moving_avg, diff_variation \n",
    "    return t + T\n",
    "\n",
    "@delegates(convergence_time)\n",
    "def indiv_convergence_time(results, max_epochs=800, **kwargs):\n",
    "    \"Similar to `convergence_time` but with each agent.\"\n",
    "    results = results['rewards']\n",
    "    times = [convergence_time({'rewards': [res[:max_epochs]]}, **kwargs) for res in results]\n",
    "    return np.array(times)\n",
    "\n",
    "def get_indiv_times(tl_eval, convergence_crit=None):\n",
    "    \"Provides convergence times from individual ratios.\"\n",
    "    default_crit = {'T': 50, 't_avg': 100, 'tol': 2e-4}\n",
    "    convergence_crit = {**default_crit, **convergence_crit} if convergence_crit is not None else default_crit\n",
    "    Bs = list(TL_evaluation.keys()); Bs.sort()\n",
    "    time_ratios, time_err = [], []\n",
    "    for b in Bs:\n",
    "        ts_tl = indiv_convergence_time(tl_eval[b]['tl'], **convergence_crit)\n",
    "        ts_0 = indiv_convergence_time(tl_eval[b]['vanilla'], **convergence_crit)\n",
    "        t0, ttl = ts_0.mean(), ts_tl.mean()\n",
    "        ratio = ttl/t0\n",
    "        ratio_std = np.sqrt((1/t0)**2*ts_tl.var() + (ttl/t0**2)**2*ts_0.var())\n",
    "        time_ratios.append(ratio)\n",
    "        time_err.append(ratio_std/np.sqrt(len(ts_0)))\n",
    "    return Bs, np.array(time_ratios), np.array(time_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    \"Unpickles from GPU to CPU\"\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def save_benchmark(benchmark, N, H, method, suffix=None):\n",
    "    bench_dir = Path(\"../benchmarks/\"); bench_dir.mkdir(exist_ok=True)\n",
    "    file_name = f\"bench_N{N}_{method}_{H.model}_B{state2str(H.linear)}_J{state2str(H.quadratic)}\"\n",
    "    if suffix is not None: file_name += f\"_{suffix}\"\n",
    "    save_path = (bench_dir/file_name).with_suffix(\".pkl\")\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(benchmark, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_benchmark(N, H, method, suffix=None):\n",
    "    bench_dir = Path(\"../benchmarks/\")\n",
    "    file_name = f\"bench_N{N}_{method}_{H.model}_B{state2str(H.linear)}_J{state2str(H.quadratic)}\"\n",
    "    if suffix is not None: file_name += f\"_{suffix}\"\n",
    "    load_path = (bench_dir/file_name).with_suffix(\".pkl\")\n",
    "    with open(load_path, \"rb\") as f:\n",
    "        benchmark = pickle.load(f)\n",
    "    return benchmark\n",
    "\n",
    "def load_checkpoint(H, maxP, ID, episode):\n",
    "    ckp_dir = Path(\"../trained_models/checkpoints/\")\n",
    "    ckp_name = f\"ckp_N{H.N}_{H.model}_{maxP}_id{ID}_e{episode}.pt\"\n",
    "    return torch.load(ckp_dir/ckp_name)\n",
    "\n",
    "def checkpoint2results(N, model, maxP, IDs, episode):\n",
    "    \"Loads checkpoints from IDs and converts them to result format.\"\n",
    "    models, envs, final_rewards, final_params, final_energies, final_optims, expl_optims = [], [], [], [], [], [], []\n",
    "    visited_states, visited_energies, visited_params, oracle_rewards, visited_rewards = [], [], [], [], []\n",
    "    for ID in IDs:\n",
    "        try:\n",
    "            ckp = load_checkpoint(N, model, maxP, ID, episode)\n",
    "            models.append(ckp['model']); envs.append(ckp['env']); final_rewards.append(ckp['final_reward'])\n",
    "            final_params.append(ckp['final_params']); final_energies.append(ckp['final_energies'])\n",
    "            final_optims.append(ckp['eval_optims']); expl_optims.append(ckp['expl_optims'])\n",
    "            visited_states.append(ckp['visited_states']); visited_energies.append(ckp['visited_energies'])\n",
    "            visited_params.append(ckp['visited_params']); oracle_rewards.append(ckp['oracle_rewards'])\n",
    "            visited_rewards.append(ckp['visited_rewards'])\n",
    "        except: print(f\"Failed to load ID{ID}\")\n",
    "    training_results = {'models': models, 'envs': envs, 'rewards': final_rewards, 'params': final_params, \n",
    "                        'energies': final_energies, 'eval_optims': final_optims, 'expl_optims': expl_optims}\n",
    "    exploration_results = {'agents': models, 'envs': envs, 'visited_states': visited_states, 'energies': visited_energies, \n",
    "                           'params': visited_params, 'oracle_rewards': oracle_rewards, 'visited_rewards': visited_rewards}\n",
    "    return {'training': training_results, 'exploration': exploration_results}\n",
    "\n",
    "def save_model(agent, H, maxP, ID):\n",
    "    agents_dir = Path(\"../trained_models/\")\n",
    "    agents_dir.mkdir(exist_ok=True)\n",
    "    if H.model == 'xy':\n",
    "        agent_name = f\"agent_N{agent.N}_{H.model}_{maxP}_id{ID}_{state2str(H.linear)}_{state2str(H.quadratic)}_g{H.g}.pt\"\n",
    "    elif H.model == 'graph': \n",
    "        agent_name = f\"agent_N{agent.N}_{H.model}_{maxP}_id{ID}.pt\"\n",
    "    else: \n",
    "        agent_name = f\"agent_N{agent.N}_{H.model}_{maxP}_id{ID}_{state2str(H.linear)}_{state2str(H.quadratic)}.pt\"\n",
    "\n",
    "    torch.save({'model': agent.model, 'state_dict': agent.model.state_dict}, agents_dir/agent_name)\n",
    "\n",
    "def load_model(H, maxP, ID):\n",
    "    agents_dir = Path(\"../trained_models/\")\n",
    "    if H.model == 'xy':\n",
    "        agent_name = f\"agent_N{H.N}_{H.model}_{maxP}_id{ID}_{state2str(H.linear)}_{state2str(H.quadratic)}_g{H.g}.pt\"\n",
    "    elif H.model == 'graph': \n",
    "        agent_name = f\"agent_N{H.N}_{H.model}_{maxP}_id{ID}.pt\"\n",
    "    else: \n",
    "        agent_name = f\"agent_N{H.N}_{H.model}_{maxP}_id{ID}_{state2str(H.linear)}_{state2str(H.quadratic)}.pt\"\n",
    "        \n",
    "    return torch.load(agents_dir/agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## State transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def simplify_layout(L):\n",
    "    \"Simplifies the given layout of the form `[np.array([0, 1]), np.array([0, 1, 2])]`.\"\n",
    "    to_simplify = []\n",
    "    for k1, sites1 in enumerate(L[:-1]):\n",
    "        if k1 not in to_simplify:\n",
    "            for k2, sites2 in enumerate(L[k1+1:]):\n",
    "                overlap = len(np.intersect1d(sites1, sites2))\n",
    "                if   overlap == len(sites1): to_simplify.append(k1); break\n",
    "                elif overlap == len(sites2): to_simplify.append(k1+1+k2)\n",
    "    return [sites for k, sites in enumerate(L) if k not in to_simplify]\n",
    "\n",
    "def fill_layout(L, N):\n",
    "    \"Fills layout with single-body terms that are missing.\"\n",
    "    for n in range(N):\n",
    "        included = any([(sites == n).any() for sites in L])\n",
    "        if not included: L.append(np.array([n]))\n",
    "    return L\n",
    "    \n",
    "def state2int(state):\n",
    "    \"Takes state vector as binary encoding of an integer.\"\n",
    "    return int(state2str(state[::-1]), 2)\n",
    "\n",
    "def state2str(state):\n",
    "    \"Takes state vector and outputs a (spaceless) string.\"\n",
    "    return ''.join(str(int(i)) if isinstance(i, (int, np.int64)) or i.is_integer() else str(i) for i in state)\n",
    "\n",
    "def state_in_list(state, state_list):\n",
    "    \"Checks whether a state vector is in a list of states.\"\n",
    "    return any((state == x).all() for x in state_list)\n",
    "    \n",
    "def T(state):\n",
    "    \"Takes state and converts it to `torch.FloatTensor`\"\n",
    "    return torch.FloatTensor(state)\n",
    "    \n",
    "def flip(state, i):\n",
    "    \"Flips constraint `i` from state.\"\n",
    "    flip_state = deepcopy(state)\n",
    "    flip_state[i] = -flip_state[i] + 1\n",
    "    return flip_state\n",
    "\n",
    "def contained_constraints(state, N):\n",
    "    \"\"\"Provides a boolean mask indicating the constraints already contained within a larger one in \n",
    "    the given state. \n",
    "    Each group larger than pairs contains 2 of the immediately smaller groups, 3 of the next,\n",
    "    4 of the next and so on. For example, a group of 5 will contain 2 groups of 4, 3 groups of 3 and 4 groups of 2.\"\"\"\n",
    "    mask = np.zeros(len(state), dtype=bool)\n",
    "    ii = np.where(state[N:] == 1)[0] + N              \n",
    "    for i in ii:\n",
    "        steps, res = i//N, i%N                   \n",
    "        for j in range(steps):\n",
    "            idx0 = j*N + res\n",
    "            idx1= idx0+steps+1-j\n",
    "            idx = np.arange(idx0, idx1)%N + j*N\n",
    "            mask[idx] = 1             \n",
    "    return mask \n",
    "    \n",
    "def action_mask(state, N):\n",
    "    \"Mask of the actions that can be performed\"\n",
    "    return np.append(contained_constraints(state, N), False) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Useful mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export    \n",
    "def dist_exp(xmin, x):\n",
    "    \"\"\"This function computes an eponential distance given a minimum value (in terms of absolute value).\"\"\"\n",
    "    return np.exp(1-x/xmin)\n",
    "\n",
    "def dist_poly(x, xmin, xmax, d):\n",
    "    \"\"\"This function computes a linear decay bound from 1 to 0 given a minimum and maximum value (in terms of \n",
    "    absolute value). Exponentiate the line to get better shapes\"\"\"\n",
    "    if np.allclose(xmin, xmax): x[:] = 1.; return x \n",
    "    else:                       return ((x-xmax)/(xmin-xmax))**d \n",
    "    \n",
    "def binomial(n, k):\n",
    "    return np.math.factorial(n)/(np.math.factorial(k)*np.math.factorial(n-k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_environment.ipynb.\n",
      "Converted 01_agents.ipynb.\n",
      "Converted 02_budget_profiles.ipynb.\n",
      "Converted 03_hamiltonian.ipynb.\n",
      "Converted 04_training.ipynb.\n",
      "Converted 05_utils.ipynb.\n",
      "Converted 06_sdp.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
